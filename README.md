# llama
Build a llama API and serve with FastAPI
